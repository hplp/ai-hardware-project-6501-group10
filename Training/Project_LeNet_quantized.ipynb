{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UpU9P3FL0R-",
        "outputId": "f4eb6ff7-a58a-48df-dd1d-5fe0b2c1115d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of FP32 Model (MB): 0.179057\n",
            "Epoch [1], Step [0], Loss: 2.3035, Accuracy: 6.25%\n",
            "Epoch [1], Step [100], Loss: 2.3023, Accuracy: 8.60%\n",
            "Epoch [1], Step [200], Loss: 2.3004, Accuracy: 10.28%\n",
            "Epoch [1], Step [300], Loss: 2.2984, Accuracy: 11.81%\n",
            "Epoch [1], Step [400], Loss: 2.2959, Accuracy: 13.58%\n",
            "Epoch [1], Step [500], Loss: 2.2923, Accuracy: 15.63%\n",
            "Epoch [1], Step [600], Loss: 2.2873, Accuracy: 17.83%\n",
            "Epoch [1], Step [700], Loss: 2.2791, Accuracy: 20.62%\n",
            "Epoch [1], Step [800], Loss: 2.2634, Accuracy: 23.69%\n",
            "Epoch [1], Step [900], Loss: 2.2244, Accuracy: 27.19%\n",
            "Epoch [2], Step [0], Loss: 1.4731, Accuracy: 60.94%\n",
            "Epoch [2], Step [100], Loss: 1.0346, Accuracy: 72.74%\n",
            "Epoch [2], Step [200], Loss: 0.8403, Accuracy: 77.15%\n",
            "Epoch [2], Step [300], Loss: 0.7302, Accuracy: 79.72%\n",
            "Epoch [2], Step [400], Loss: 0.6480, Accuracy: 81.82%\n",
            "Epoch [2], Step [500], Loss: 0.5895, Accuracy: 83.36%\n",
            "Epoch [2], Step [600], Loss: 0.5454, Accuracy: 84.51%\n",
            "Epoch [2], Step [700], Loss: 0.5122, Accuracy: 85.34%\n",
            "Epoch [2], Step [800], Loss: 0.4837, Accuracy: 86.10%\n",
            "Epoch [2], Step [900], Loss: 0.4586, Accuracy: 86.76%\n",
            "Epoch [3], Step [0], Loss: 0.3549, Accuracy: 90.62%\n",
            "Epoch [3], Step [100], Loss: 0.2354, Accuracy: 92.85%\n",
            "Epoch [3], Step [200], Loss: 0.2287, Accuracy: 92.99%\n",
            "Epoch [3], Step [300], Loss: 0.2234, Accuracy: 93.19%\n",
            "Epoch [3], Step [400], Loss: 0.2199, Accuracy: 93.33%\n",
            "Epoch [3], Step [500], Loss: 0.2173, Accuracy: 93.45%\n",
            "Epoch [3], Step [600], Loss: 0.2131, Accuracy: 93.58%\n",
            "Epoch [3], Step [700], Loss: 0.2073, Accuracy: 93.75%\n",
            "Epoch [3], Step [800], Loss: 0.2034, Accuracy: 93.83%\n",
            "Epoch [3], Step [900], Loss: 0.1997, Accuracy: 93.95%\n",
            "Epoch [4], Step [0], Loss: 0.1995, Accuracy: 95.31%\n",
            "Epoch [4], Step [100], Loss: 0.1788, Accuracy: 94.46%\n",
            "Epoch [4], Step [200], Loss: 0.1607, Accuracy: 95.00%\n",
            "Epoch [4], Step [300], Loss: 0.1571, Accuracy: 95.13%\n",
            "Epoch [4], Step [400], Loss: 0.1595, Accuracy: 95.04%\n",
            "Epoch [4], Step [500], Loss: 0.1581, Accuracy: 95.08%\n",
            "Epoch [4], Step [600], Loss: 0.1547, Accuracy: 95.23%\n",
            "Epoch [4], Step [700], Loss: 0.1529, Accuracy: 95.32%\n",
            "Epoch [4], Step [800], Loss: 0.1487, Accuracy: 95.43%\n",
            "Epoch [4], Step [900], Loss: 0.1461, Accuracy: 95.51%\n",
            "Epoch [5], Step [0], Loss: 0.0695, Accuracy: 96.88%\n",
            "Epoch [5], Step [100], Loss: 0.1138, Accuracy: 96.49%\n",
            "Epoch [5], Step [200], Loss: 0.1226, Accuracy: 96.15%\n",
            "Epoch [5], Step [300], Loss: 0.1203, Accuracy: 96.13%\n",
            "Epoch [5], Step [400], Loss: 0.1204, Accuracy: 96.14%\n",
            "Epoch [5], Step [500], Loss: 0.1208, Accuracy: 96.20%\n",
            "Epoch [5], Step [600], Loss: 0.1194, Accuracy: 96.28%\n",
            "Epoch [5], Step [700], Loss: 0.1191, Accuracy: 96.31%\n",
            "Epoch [5], Step [800], Loss: 0.1182, Accuracy: 96.34%\n",
            "Epoch [5], Step [900], Loss: 0.1171, Accuracy: 96.37%\n",
            "Epoch [6], Step [0], Loss: 0.0753, Accuracy: 96.88%\n",
            "Epoch [6], Step [100], Loss: 0.1103, Accuracy: 96.55%\n",
            "Epoch [6], Step [200], Loss: 0.1073, Accuracy: 96.63%\n",
            "Epoch [6], Step [300], Loss: 0.1041, Accuracy: 96.80%\n",
            "Epoch [6], Step [400], Loss: 0.1032, Accuracy: 96.88%\n",
            "Epoch [6], Step [500], Loss: 0.1037, Accuracy: 96.86%\n",
            "Epoch [6], Step [600], Loss: 0.1026, Accuracy: 96.89%\n",
            "Epoch [6], Step [700], Loss: 0.1017, Accuracy: 96.92%\n",
            "Epoch [6], Step [800], Loss: 0.1009, Accuracy: 96.94%\n",
            "Epoch [6], Step [900], Loss: 0.0990, Accuracy: 96.99%\n",
            "Epoch [7], Step [0], Loss: 0.0665, Accuracy: 98.44%\n",
            "Epoch [7], Step [100], Loss: 0.0925, Accuracy: 97.29%\n",
            "Epoch [7], Step [200], Loss: 0.0850, Accuracy: 97.40%\n",
            "Epoch [7], Step [300], Loss: 0.0837, Accuracy: 97.40%\n",
            "Epoch [7], Step [400], Loss: 0.0851, Accuracy: 97.38%\n",
            "Epoch [7], Step [500], Loss: 0.0850, Accuracy: 97.37%\n",
            "Epoch [7], Step [600], Loss: 0.0860, Accuracy: 97.32%\n",
            "Epoch [7], Step [700], Loss: 0.0866, Accuracy: 97.34%\n",
            "Epoch [7], Step [800], Loss: 0.0862, Accuracy: 97.35%\n",
            "Epoch [7], Step [900], Loss: 0.0866, Accuracy: 97.32%\n",
            "Epoch [8], Step [0], Loss: 0.0712, Accuracy: 96.88%\n",
            "Epoch [8], Step [100], Loss: 0.0863, Accuracy: 97.34%\n",
            "Epoch [8], Step [200], Loss: 0.0856, Accuracy: 97.27%\n",
            "Epoch [8], Step [300], Loss: 0.0804, Accuracy: 97.41%\n",
            "Epoch [8], Step [400], Loss: 0.0802, Accuracy: 97.50%\n",
            "Epoch [8], Step [500], Loss: 0.0792, Accuracy: 97.58%\n",
            "Epoch [8], Step [600], Loss: 0.0771, Accuracy: 97.62%\n",
            "Epoch [8], Step [700], Loss: 0.0762, Accuracy: 97.64%\n",
            "Epoch [8], Step [800], Loss: 0.0767, Accuracy: 97.64%\n",
            "Epoch [8], Step [900], Loss: 0.0769, Accuracy: 97.63%\n",
            "Epoch [9], Step [0], Loss: 0.0969, Accuracy: 96.88%\n",
            "Epoch [9], Step [100], Loss: 0.0743, Accuracy: 97.66%\n",
            "Epoch [9], Step [200], Loss: 0.0700, Accuracy: 97.88%\n",
            "Epoch [9], Step [300], Loss: 0.0714, Accuracy: 97.77%\n",
            "Epoch [9], Step [400], Loss: 0.0716, Accuracy: 97.77%\n",
            "Epoch [9], Step [500], Loss: 0.0734, Accuracy: 97.70%\n",
            "Epoch [9], Step [600], Loss: 0.0726, Accuracy: 97.73%\n",
            "Epoch [9], Step [700], Loss: 0.0717, Accuracy: 97.75%\n",
            "Epoch [9], Step [800], Loss: 0.0717, Accuracy: 97.75%\n",
            "Epoch [9], Step [900], Loss: 0.0706, Accuracy: 97.80%\n",
            "Epoch [10], Step [0], Loss: 0.0448, Accuracy: 98.44%\n",
            "Epoch [10], Step [100], Loss: 0.0643, Accuracy: 98.04%\n",
            "Epoch [10], Step [200], Loss: 0.0669, Accuracy: 98.01%\n",
            "Epoch [10], Step [300], Loss: 0.0672, Accuracy: 98.02%\n",
            "Epoch [10], Step [400], Loss: 0.0650, Accuracy: 98.02%\n",
            "Epoch [10], Step [500], Loss: 0.0651, Accuracy: 98.00%\n",
            "Epoch [10], Step [600], Loss: 0.0644, Accuracy: 98.01%\n",
            "Epoch [10], Step [700], Loss: 0.0644, Accuracy: 98.02%\n",
            "Epoch [10], Step [800], Loss: 0.0634, Accuracy: 98.05%\n",
            "Epoch [10], Step [900], Loss: 0.0635, Accuracy: 98.05%\n",
            "Finished Training\n",
            "Accuracy of the model: 98.26%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# Define the transformation\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load MNIST dataset\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Utility functions\n",
        "def print_size_of_model(model, name=\"Model\"):\n",
        "    \"\"\" Prints the real size of the model \"\"\"\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print(f'Size of {name} (MB): {os.path.getsize(\"temp.p\") / 1e6}')\n",
        "    os.remove('temp.p')\n",
        "\n",
        "def accuracy(output, target):\n",
        "    with torch.no_grad():\n",
        "        batch_size = target.size(0)\n",
        "        _, pred = output.topk(1, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "        return correct[:1].view(-1).float().sum(0, keepdim=True).mul_(100.0 / batch_size).item()\n",
        "\n",
        "# Define the LeNet model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, q=False):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, bias=False)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(256, 120, bias=False)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(120, 84, bias=False)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(84, 10, bias=False)\n",
        "        self.q = q\n",
        "        if q:\n",
        "            self.quant = torch.quantization.QuantStub()\n",
        "            self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self.q:\n",
        "            x = self.quant(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.fc3(x)\n",
        "        if self.q:\n",
        "            x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "# Train function\n",
        "def train(model, dataloader, cuda=False):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    model.train()\n",
        "    for epoch in range(10):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for i, data in enumerate(dataloader):\n",
        "            inputs, labels = data\n",
        "            if cuda:\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            if i % 100 == 0:\n",
        "                print(f'Epoch [{epoch + 1}], Step [{i}], Loss: {running_loss / (i + 1):.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "# Test function\n",
        "def test(model, dataloader, cuda=False):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            inputs, labels = data\n",
        "            if cuda:\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the model: {accuracy}%')\n",
        "    return accuracy\n",
        "\n",
        "# Train and test FP32 model\n",
        "net_fp32 = Net(q=False).cuda()\n",
        "print_size_of_model(net_fp32, \"FP32 Model\")\n",
        "train(net_fp32, trainloader, cuda=True)\n",
        "score_fp32 = test(net_fp32, testloader, cuda=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained FP32 model\n",
        "torch.save(net_fp32.state_dict(), \"lenet_int32.pth\")\n",
        "print(\"Trained model saved as lenet_int32.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu61oaFYHB6B",
        "outputId": "c98d3e58-18e5-4a74-df05-306681683202"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model saved as lenet_int32.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Simulate INT4 quantization and dequantization\n",
        "def int4_quantize(tensor):\n",
        "    scale = 7 / tensor.abs().max()  # Scale factor to map to INT4 range\n",
        "    quantized_tensor = (tensor * scale).clamp(-7, 7).round().char()  # Quantize to INT4\n",
        "    return quantized_tensor, scale\n",
        "\n",
        "def int4_dequantize(quantized_tensor, scale):\n",
        "    return quantized_tensor.float() / scale  # Dequantize back to float\n",
        "\n",
        "# Simulate quantized forward pass for INT4 with input quantization\n",
        "def quantized_forward_int4_with_input_quant(model, x):\n",
        "    with torch.no_grad():\n",
        "        # Quantize the input\n",
        "        x_q, input_scale = int4_quantize(x)  # Quantize input and get scale\n",
        "\n",
        "        # Manually quantizing each layer's weights\n",
        "        conv1_w_q, conv1_scale = int4_quantize(model.conv1.weight.data)\n",
        "        conv2_w_q, conv2_scale = int4_quantize(model.conv2.weight.data)\n",
        "        fc1_w_q, fc1_scale = int4_quantize(model.fc1.weight.data)\n",
        "        fc2_w_q, fc2_scale = int4_quantize(model.fc2.weight.data)\n",
        "        fc3_w_q, fc3_scale = int4_quantize(model.fc3.weight.data)\n",
        "\n",
        "        # Forward pass with dequantized weights\n",
        "        x = F.conv2d(int4_dequantize(x_q, input_scale), int4_dequantize(conv1_w_q, conv1_scale), stride=1, padding=0)\n",
        "        x = model.relu1(x)\n",
        "        x = model.pool1(x)\n",
        "\n",
        "        x_q, input_scale = int4_quantize(x)  # Re-quantize the intermediate activation\n",
        "\n",
        "        x = F.conv2d(int4_dequantize(x_q, input_scale), int4_dequantize(conv2_w_q, conv2_scale), stride=1, padding=0)\n",
        "        x = model.relu2(x)\n",
        "        x = model.pool2(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor correctly\n",
        "\n",
        "        # Dequantize and apply the fully connected layers\n",
        "        x_q, input_scale = int4_quantize(x)  # Quantize the flattened output before fully connected layers\n",
        "\n",
        "        x = F.linear(int4_dequantize(x_q, input_scale), int4_dequantize(fc1_w_q, fc1_scale))\n",
        "        x = model.relu3(x)\n",
        "\n",
        "        x_q, input_scale = int4_quantize(x)  # Re-quantize before the next layer\n",
        "\n",
        "        x = F.linear(int4_dequantize(x_q, input_scale), int4_dequantize(fc2_w_q, fc2_scale))\n",
        "        x = model.relu4(x)\n",
        "\n",
        "        x_q, input_scale = int4_quantize(x)  # Re-quantize before the final layer\n",
        "\n",
        "        x = F.linear(int4_dequantize(x_q, input_scale), int4_dequantize(fc3_w_q, fc3_scale))\n",
        "\n",
        "    return x\n",
        "\n",
        "# Quantized model testing function for INT4 with input quantization\n",
        "def test_quantized_int4_with_input_quant(model, dataloader, cuda=False):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            inputs, labels = data\n",
        "            if cuda:\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "            outputs = quantized_forward_int4_with_input_quant(model, inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the quantized model (INT4) with input quantization on the test images: {accuracy}%')\n",
        "    return accuracy\n",
        "\n",
        "# Now test the INT4 quantized model\n",
        "print(\"Testing INT4 Quantized Model with Input Quantization...\")\n",
        "score_int4 = test_quantized_int4_with_input_quant(net_fp32, testloader, cuda=True)\n",
        "\n",
        "# Print model sizes and accuracies for comparison\n",
        "print(f'FP32 Model Accuracy: {score_fp32}%')\n",
        "print(f'INT4 Quantized Model Accuracy: {score_int4}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RQx7vwKNij3",
        "outputId": "32086605-1107-4089-c888-e1e5269fa0c7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing INT4 Quantized Model with Input Quantization...\n",
            "Accuracy of the quantized model (INT4) with input quantization on the test images: 96.73%\n",
            "FP32 Model Accuracy: 98.26%\n",
            "INT4 Quantized Model Accuracy: 96.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the INT4 quantized model\n",
        "int4_model_state = {\n",
        "    \"conv1_weight\": int4_quantize(net_fp32.conv1.weight.data),\n",
        "    \"conv2_weight\": int4_quantize(net_fp32.conv2.weight.data),\n",
        "    \"fc1_weight\": int4_quantize(net_fp32.fc1.weight.data),\n",
        "    \"fc2_weight\": int4_quantize(net_fp32.fc2.weight.data),\n",
        "    \"fc3_weight\": int4_quantize(net_fp32.fc3.weight.data),\n",
        "}\n",
        "torch.save(int4_model_state, \"lenet_int4.pth\")\n",
        "print(\"Quantized INT4 model saved as lenet_int4.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pCH9Nt3HyUt",
        "outputId": "3eb702c0-2747-4053-ec99-adee5dfdfc92"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized INT4 model saved as lenet_int4.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INT16 quantization\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Simulate INT16 quantization and dequantization\n",
        "def int16_quantize(tensor):\n",
        "    scale = 32767 / tensor.abs().max()  # Scale factor to map to INT16 range\n",
        "    quantized_tensor = (tensor * scale).clamp(-32767, 32767).round().short()  # Quantize to INT16\n",
        "    return quantized_tensor, scale\n",
        "\n",
        "def int16_dequantize(quantized_tensor, scale):\n",
        "    return quantized_tensor.float() / scale  # Dequantize back to float\n",
        "\n",
        "# Simulate quantized forward pass for INT16 with input quantization\n",
        "def quantized_forward_int16_with_input_quant(model, x):\n",
        "    with torch.no_grad():\n",
        "        # Quantize the input\n",
        "        x_q, input_scale = int16_quantize(x)  # Quantize input and get scale\n",
        "\n",
        "        # Manually quantizing each layer's weights\n",
        "        conv1_w_q, conv1_scale = int16_quantize(model.conv1.weight.data)\n",
        "        conv2_w_q, conv2_scale = int16_quantize(model.conv2.weight.data)\n",
        "        fc1_w_q, fc1_scale = int16_quantize(model.fc1.weight.data)\n",
        "        fc2_w_q, fc2_scale = int16_quantize(model.fc2.weight.data)\n",
        "        fc3_w_q, fc3_scale = int16_quantize(model.fc3.weight.data)\n",
        "\n",
        "        # Forward pass with dequantized weights\n",
        "        x = F.conv2d(int16_dequantize(x_q, input_scale), int16_dequantize(conv1_w_q, conv1_scale), stride=1, padding=0)\n",
        "        x = model.relu1(x)\n",
        "        x = model.pool1(x)\n",
        "\n",
        "        x_q, input_scale = int16_quantize(x)  # Re-quantize the intermediate activation\n",
        "\n",
        "        x = F.conv2d(int16_dequantize(x_q, input_scale), int16_dequantize(conv2_w_q, conv2_scale), stride=1, padding=0)\n",
        "        x = model.relu2(x)\n",
        "        x = model.pool2(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor correctly\n",
        "\n",
        "        # Dequantize and apply the fully connected layers\n",
        "        x_q, input_scale = int16_quantize(x)  # Quantize the flattened output before fully connected layers\n",
        "\n",
        "        x = F.linear(int16_dequantize(x_q, input_scale), int16_dequantize(fc1_w_q, fc1_scale))\n",
        "        x = model.relu3(x)\n",
        "\n",
        "        x_q, input_scale = int16_quantize(x)  # Re-quantize before the next layer\n",
        "\n",
        "        x = F.linear(int16_dequantize(x_q, input_scale), int16_dequantize(fc2_w_q, fc2_scale))\n",
        "        x = model.relu4(x)\n",
        "\n",
        "        x_q, input_scale = int16_quantize(x)  # Re-quantize before the final layer\n",
        "\n",
        "        x = F.linear(int16_dequantize(x_q, input_scale), int16_dequantize(fc3_w_q, fc3_scale))\n",
        "\n",
        "    return x\n",
        "\n",
        "# Quantized model testing function for INT16 with input quantization\n",
        "def test_quantized_int16_with_input_quant(model, dataloader, cuda=False):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            inputs, labels = data\n",
        "            if cuda:\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "            outputs = quantized_forward_int16_with_input_quant(model, inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the quantized model (INT16) with input quantization on the test images: {accuracy}%')\n",
        "    return accuracy\n",
        "\n",
        "# Now test the INT16 quantized model\n",
        "print(\"Testing INT16 Quantized Model with Input Quantization...\")\n",
        "score_int16 = test_quantized_int16_with_input_quant(net_fp32, testloader, cuda=True)\n",
        "\n",
        "# Print model sizes and accuracies for comparison\n",
        "print(f'FP32 Model Accuracy: {score_fp32}%')\n",
        "print(f'INT16 Quantized Model Accuracy: {score_int16}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_5dJaE6OGlm",
        "outputId": "151232cd-4e34-4da2-f7a9-df3d18db012b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing INT16 Quantized Model with Input Quantization...\n",
            "Accuracy of the quantized model (INT16) with input quantization on the test images: 98.26%\n",
            "FP32 Model Accuracy: 98.26%\n",
            "INT16 Quantized Model Accuracy: 98.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the INT16 quantized model\n",
        "int16_model_state = {\n",
        "    \"conv1_weight\": int16_quantize(net_fp32.conv1.weight.data),\n",
        "    \"conv2_weight\": int16_quantize(net_fp32.conv2.weight.data),\n",
        "    \"fc1_weight\": int16_quantize(net_fp32.fc1.weight.data),\n",
        "    \"fc2_weight\": int16_quantize(net_fp32.fc2.weight.data),\n",
        "    \"fc3_weight\": int16_quantize(net_fp32.fc3.weight.data),\n",
        "}\n",
        "torch.save(int16_model_state, \"lenet_int16.pth\")\n",
        "print(\"Quantized INT16 model saved as lenet_int16.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1FkIhNZIOoR",
        "outputId": "59b34820-f6b2-4173-9bbf-49d32c1b6a4b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized INT16 model saved as lenet_int16.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INT8:\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Simulate INT8 quantization and dequantization\n",
        "def int8_quantize(tensor):\n",
        "    scale = 127 / tensor.abs().max()  # Scale factor to map to INT8 range\n",
        "    quantized_tensor = (tensor * scale).clamp(-127, 127).round().char()  # Quantize to INT8\n",
        "    return quantized_tensor, scale\n",
        "\n",
        "def int8_dequantize(quantized_tensor, scale):\n",
        "    return quantized_tensor.float() / scale  # Dequantize back to float\n",
        "\n",
        "# Simulate quantized forward pass for INT8 with input quantization\n",
        "def quantized_forward_int8_with_input_quant(model, x):\n",
        "    with torch.no_grad():\n",
        "        # Quantize the input\n",
        "        x_q, input_scale = int8_quantize(x)  # Quantize input and get scale\n",
        "\n",
        "        # Manually quantizing each layer's weights\n",
        "        conv1_w_q, conv1_scale = int8_quantize(model.conv1.weight.data)\n",
        "        conv2_w_q, conv2_scale = int8_quantize(model.conv2.weight.data)\n",
        "        fc1_w_q, fc1_scale = int8_quantize(model.fc1.weight.data)\n",
        "        fc2_w_q, fc2_scale = int8_quantize(model.fc2.weight.data)\n",
        "        fc3_w_q, fc3_scale = int8_quantize(model.fc3.weight.data)\n",
        "\n",
        "        # Forward pass with dequantized weights\n",
        "        x = F.conv2d(int8_dequantize(x_q, input_scale), int8_dequantize(conv1_w_q, conv1_scale), stride=1, padding=0)\n",
        "        x = model.relu1(x)\n",
        "        x = model.pool1(x)\n",
        "\n",
        "        x_q, input_scale = int8_quantize(x)  # Re-quantize the intermediate activation\n",
        "\n",
        "        x = F.conv2d(int8_dequantize(x_q, input_scale), int8_dequantize(conv2_w_q, conv2_scale), stride=1, padding=0)\n",
        "        x = model.relu2(x)\n",
        "        x = model.pool2(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor correctly\n",
        "\n",
        "        # Dequantize and apply the fully connected layers\n",
        "        x_q, input_scale = int8_quantize(x)  # Quantize the flattened output before fully connected layers\n",
        "\n",
        "        x = F.linear(int8_dequantize(x_q, input_scale), int8_dequantize(fc1_w_q, fc1_scale))\n",
        "        x = model.relu3(x)\n",
        "\n",
        "        x_q, input_scale = int8_quantize(x)  # Re-quantize before the next layer\n",
        "\n",
        "        x = F.linear(int8_dequantize(x_q, input_scale), int8_dequantize(fc2_w_q, fc2_scale))\n",
        "        x = model.relu4(x)\n",
        "\n",
        "        x_q, input_scale = int8_quantize(x)  # Re-quantize before the final layer\n",
        "\n",
        "        x = F.linear(int8_dequantize(x_q, input_scale), int8_dequantize(fc3_w_q, fc3_scale))\n",
        "\n",
        "    return x\n",
        "\n",
        "# Quantized model testing function for INT8 with input quantization\n",
        "def test_quantized_int8_with_input_quant(model, dataloader, cuda=False):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            inputs, labels = data\n",
        "            if cuda:\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "            outputs = quantized_forward_int8_with_input_quant(model, inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the quantized model (INT8) with input quantization on the test images: {accuracy}%')\n",
        "    return accuracy\n",
        "\n",
        "# Now test the INT8 quantized model\n",
        "print(\"Testing INT8 Quantized Model with Input Quantization...\")\n",
        "score_int8 = test_quantized_int8_with_input_quant(net_fp32, testloader, cuda=True)\n",
        "\n",
        "# Print model sizes and accuracies for comparison\n",
        "print(f'FP32 Model Accuracy: {score_fp32}%')\n",
        "print(f'INT8 Quantized Model Accuracy: {score_int8}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lcnJm-ZOPcA",
        "outputId": "c278e0f6-a720-4037-fa28-f323f1e2dcb8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing INT8 Quantized Model with Input Quantization...\n",
            "Accuracy of the quantized model (INT8) with input quantization on the test images: 98.15%\n",
            "FP32 Model Accuracy: 98.17%\n",
            "INT8 Quantized Model Accuracy: 98.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the INT16 quantized model\n",
        "int8_model_state = {\n",
        "    \"conv1_weight\": int8_quantize(net_fp32.conv1.weight.data),\n",
        "    \"conv2_weight\": int8_quantize(net_fp32.conv2.weight.data),\n",
        "    \"fc1_weight\": int8_quantize(net_fp32.fc1.weight.data),\n",
        "    \"fc2_weight\": int8_quantize(net_fp32.fc2.weight.data),\n",
        "    \"fc3_weight\": int8_quantize(net_fp32.fc3.weight.data),\n",
        "}\n",
        "torch.save(int8_model_state, \"lenet_int8.pth\")\n",
        "print(\"Quantized INT8 model saved as lenet_int8.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7rsAx4BIsAK",
        "outputId": "515d7804-66ec-47cf-eb42-84e341734cf5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized INT8 model saved as lenet_int8.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model sizes and accuracies for comparison\n",
        "print(f'FP32 Model Accuracy: {score_fp32}%')\n",
        "print(f'INT16 Quantized Model Accuracy: {score_int16}%')\n",
        "print(f'INT8 Quantized Model Accuracy: {score_int8}%')\n",
        "print(f'INT4 Quantized Model Accuracy: {score_int4}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTcpEl0COSqu",
        "outputId": "fa871881-cb54-4cbe-8559-7d547725fc58"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FP32 Model Accuracy: 98.17%\n",
            "INT4 Quantized Model Accuracy: 96.93%\n",
            "INT8 Quantized Model Accuracy: 98.15%\n",
            "INT16 Quantized Model Accuracy: 98.16%\n"
          ]
        }
      ]
    }
  ]
}