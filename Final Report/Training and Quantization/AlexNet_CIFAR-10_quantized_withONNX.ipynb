{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb42edd5-e344-4557-ab85-733879b0b548",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/50], Loss: 2.0544, Accuracy: 22.85%\n",
      "Epoch [2/50], Loss: 1.6821, Accuracy: 37.21%\n",
      "Epoch [3/50], Loss: 1.5008, Accuracy: 44.91%\n",
      "Epoch [4/50], Loss: 1.3697, Accuracy: 50.18%\n",
      "Epoch [5/50], Loss: 1.2640, Accuracy: 54.28%\n",
      "Epoch [6/50], Loss: 1.1840, Accuracy: 57.44%\n",
      "Epoch [7/50], Loss: 1.1102, Accuracy: 60.22%\n",
      "Epoch [8/50], Loss: 1.0598, Accuracy: 62.25%\n",
      "Epoch [9/50], Loss: 0.9923, Accuracy: 64.80%\n",
      "Epoch [10/50], Loss: 0.9548, Accuracy: 66.30%\n",
      "Epoch [11/50], Loss: 0.9277, Accuracy: 67.48%\n",
      "Epoch [12/50], Loss: 0.9016, Accuracy: 68.24%\n",
      "Epoch [13/50], Loss: 0.8681, Accuracy: 69.70%\n",
      "Epoch [14/50], Loss: 0.8521, Accuracy: 70.26%\n",
      "Epoch [15/50], Loss: 0.8356, Accuracy: 70.47%\n",
      "Epoch [16/50], Loss: 0.7432, Accuracy: 73.89%\n",
      "Epoch [17/50], Loss: 0.7149, Accuracy: 74.88%\n",
      "Epoch [18/50], Loss: 0.7142, Accuracy: 75.09%\n",
      "Epoch [19/50], Loss: 0.6960, Accuracy: 75.60%\n",
      "Epoch [20/50], Loss: 0.6817, Accuracy: 76.21%\n",
      "Epoch [21/50], Loss: 0.6666, Accuracy: 76.84%\n",
      "Epoch [22/50], Loss: 0.6552, Accuracy: 77.28%\n",
      "Epoch [23/50], Loss: 0.6438, Accuracy: 77.41%\n",
      "Epoch [24/50], Loss: 0.6327, Accuracy: 77.80%\n",
      "Epoch [25/50], Loss: 0.6222, Accuracy: 78.17%\n",
      "Epoch [26/50], Loss: 0.6147, Accuracy: 78.53%\n",
      "Epoch [27/50], Loss: 0.6131, Accuracy: 78.62%\n",
      "Epoch [28/50], Loss: 0.5985, Accuracy: 79.24%\n",
      "Epoch [29/50], Loss: 0.5943, Accuracy: 79.30%\n",
      "Epoch [30/50], Loss: 0.5813, Accuracy: 79.66%\n",
      "Epoch [31/50], Loss: 0.5467, Accuracy: 80.82%\n",
      "Epoch [32/50], Loss: 0.5365, Accuracy: 81.26%\n",
      "Epoch [33/50], Loss: 0.5279, Accuracy: 81.44%\n",
      "Epoch [34/50], Loss: 0.5207, Accuracy: 81.90%\n",
      "Epoch [35/50], Loss: 0.5170, Accuracy: 81.84%\n",
      "Epoch [36/50], Loss: 0.5099, Accuracy: 82.11%\n",
      "Epoch [37/50], Loss: 0.5050, Accuracy: 82.34%\n",
      "Epoch [38/50], Loss: 0.4987, Accuracy: 82.58%\n",
      "Epoch [39/50], Loss: 0.5081, Accuracy: 82.26%\n",
      "Epoch [40/50], Loss: 0.4954, Accuracy: 82.77%\n",
      "Epoch [41/50], Loss: 0.4964, Accuracy: 82.54%\n",
      "Epoch [42/50], Loss: 0.4895, Accuracy: 82.83%\n",
      "Epoch [43/50], Loss: 0.4859, Accuracy: 83.06%\n",
      "Epoch [44/50], Loss: 0.4848, Accuracy: 83.02%\n",
      "Epoch [45/50], Loss: 0.4880, Accuracy: 82.71%\n",
      "Epoch [46/50], Loss: 0.4523, Accuracy: 84.03%\n",
      "Epoch [47/50], Loss: 0.4502, Accuracy: 84.18%\n",
      "Epoch [48/50], Loss: 0.4484, Accuracy: 84.07%\n",
      "Epoch [49/50], Loss: 0.4447, Accuracy: 84.38%\n",
      "Epoch [50/50], Loss: 0.4426, Accuracy: 84.37%\n",
      "FP32 model saved as alexnet_fp3_CIFAR.pth\n",
      "Accuracy: 83.73%\n",
      "FP32 Model Accuracy: 83.73%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "# Define AlexNet Model\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, q=False):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),  # Conv1\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),  # Conv2\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),  # Conv3\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),  # Conv4\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),  # Conv5\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),  # FC6\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),  # FC7\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 10),  # FC8 (output for CIFAR-10)\n",
    "        )\n",
    "        self.q = q\n",
    "        if q:\n",
    "            self.quant = torch.quantization.QuantStub()\n",
    "            self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.q:\n",
    "            x = self.quant(x)\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.classifier(x)\n",
    "        if self.q:\n",
    "            x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "    import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# Enhanced data augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.Resize((224, 224)),  # Resize for AlexNet input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Updated dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=512, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=512, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Fine-tuned training function\n",
    "def train(model, dataloader, epochs=50, cuda=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # Using Adam with weight decay\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)  # Reduce LR every 15 epochs\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data\n",
    "            if cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        scheduler.step()  # Adjust learning rate\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(dataloader):.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Testing function\n",
    "def test(model, dataloader, cuda=False):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            if cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy}%')\n",
    "    return accuracy\n",
    "\n",
    "# Train FP32 model\n",
    "alexnet_fp32 = AlexNet(q=False).cuda()\n",
    "train(alexnet_fp32, trainloader, epochs=50, cuda=True)\n",
    "torch.save(alexnet_fp32.state_dict(), \"alexnet_fp32_CIFAR.pth\")\n",
    "print(\"FP32 model saved as alexnet_fp3_CIFAR.pth\")\n",
    "\n",
    "# Test FP32 model\n",
    "fp32_accuracy = test(alexnet_fp32, testloader, cuda=True)\n",
    "print(f\"FP32 Model Accuracy: {fp32_accuracy}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75b42062-ccd5-4768-a94b-76bdd59b2fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Per-Layer INT8 Quantized Model...\n",
      "Quantized Model Accuracy: 49.83%\n",
      "INT8 Quantized Model Accuracy: 49.83%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Per-Layer Quantization\n",
    "def per_layer_quantize(tensor):\n",
    "    max_val = tensor.abs().amax()\n",
    "    scale = 127 / max_val\n",
    "    quantized_tensor = (tensor * scale).clamp(-127, 127).round().char()\n",
    "    return quantized_tensor, scale\n",
    "\n",
    "def per_layer_dequantize(quantized_tensor, scale):\n",
    "    return quantized_tensor.float() / scale\n",
    "\n",
    "# Quantized Forward Pass\n",
    "def quantized_forward_per_layer(model, x, quantize_fn, dequantize_fn):\n",
    "    with torch.no_grad():\n",
    "        weights_q = {}\n",
    "        scales = {}\n",
    "\n",
    "        # Quantize weights\n",
    "        for name, param in model.named_parameters():\n",
    "            weights_q[name], scales[name] = quantize_fn(param.data)\n",
    "\n",
    "        # Forward pass through features\n",
    "        for i, layer in enumerate(model.features):\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                key = f\"features.{i}.weight\"\n",
    "                activation_scale = 127 / (x.abs().amax() + 1e-8)\n",
    "                x = F.conv2d(\n",
    "                    x / activation_scale,\n",
    "                    dequantize_fn(weights_q[key], scales[key]),\n",
    "                    stride=layer.stride,\n",
    "                    padding=layer.padding\n",
    "                )\n",
    "                x = (x * activation_scale).clamp(-127, 127).round().char()\n",
    "            elif isinstance(layer, nn.MaxPool2d):\n",
    "                x = x.float()  # Convert back to Float for pooling\n",
    "                x = layer(x)\n",
    "                activation_scale = 127 / (x.abs().amax() + 1e-8)  # Recompute scale\n",
    "                x = (x * activation_scale).clamp(-127, 127).round().char()  # Requantize\n",
    "            elif isinstance(layer, nn.ReLU):\n",
    "                x = x.float()  # Convert back to Float for ReLU\n",
    "                x = layer(x)\n",
    "                activation_scale = 127 / (x.abs().amax() + 1e-8)  # Recompute scale\n",
    "                x = (x * activation_scale).clamp(-127, 127).round().char()  # Requantize\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Forward pass through classifier\n",
    "        for i, layer in enumerate(model.classifier):\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                key = f\"classifier.{i}.weight\"\n",
    "                activation_scale = 127 / (x.abs().amax() + 1e-8)\n",
    "                x = F.linear(\n",
    "                    x / activation_scale,\n",
    "                    dequantize_fn(weights_q[key], scales[key])\n",
    "                )\n",
    "                x = (x * activation_scale).clamp(-127, 127).round().char()\n",
    "            elif isinstance(layer, nn.ReLU) or isinstance(layer, nn.Dropout):\n",
    "                x = x.float()  # Convert back to Float for ReLU or Dropout\n",
    "                x = layer(x)\n",
    "                activation_scale = 127 / (x.abs().amax() + 1e-8)  # Recompute scale\n",
    "                x = (x * activation_scale).clamp(-127, 127).round().char()  # Requantize\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Quantized Model Testing\n",
    "def test_quantized_per_layer(model, dataloader, device, quantize_fn, dequantize_fn):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = quantized_forward_per_layer(model, inputs, quantize_fn, dequantize_fn)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Quantized Model Accuracy: {accuracy}%\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Quantized Testing for CIFAR-10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "alexnet_fp32.load_state_dict(torch.load(\"alexnet_fp32_CIFAR.pth\"))\n",
    "print(\"Testing Per-Layer INT8 Quantized Model...\")\n",
    "int8_accuracy = test_quantized_per_layer(alexnet_fp32, testloader, device, per_layer_quantize, per_layer_dequantize)\n",
    "print(f\"INT8 Quantized Model Accuracy: {int8_accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "521b4561-20d2-424f-ad80-3b8140671455",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing INT16 Quantized Model...\n",
      "Quantized Model Accuracy: 50.0%\n",
      "INT16 Quantized Model Accuracy: 50.0%\n"
     ]
    }
   ],
   "source": [
    "# INT16 Per-Layer Quantization\n",
    "def per_layer_quantize_int16(tensor):\n",
    "    max_val = tensor.abs().amax()\n",
    "    scale = 32767 / max_val\n",
    "    quantized_tensor = (tensor * scale).clamp(-32767, 32767).round().short()\n",
    "    return quantized_tensor, scale\n",
    "\n",
    "def per_layer_dequantize_int16(quantized_tensor, scale):\n",
    "    return quantized_tensor.float() / scale\n",
    "\n",
    "# INT16 Quantized Forward Pass\n",
    "def quantized_forward_per_layer_int16(model, x, quantize_fn, dequantize_fn):\n",
    "    with torch.no_grad():\n",
    "        weights_q = {}\n",
    "        scales = {}\n",
    "\n",
    "        # Quantize weights\n",
    "        for name, param in model.named_parameters():\n",
    "            weights_q[name], scales[name] = quantize_fn(param.data)\n",
    "\n",
    "        # Forward pass through features\n",
    "        for i, layer in enumerate(model.features):\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                key = f\"features.{i}.weight\"\n",
    "                activation_scale = 32767 / (x.abs().amax() + 1e-8)\n",
    "                x = F.conv2d(\n",
    "                    x / activation_scale,\n",
    "                    dequantize_fn(weights_q[key], scales[key]),\n",
    "                    stride=layer.stride,\n",
    "                    padding=layer.padding\n",
    "                )\n",
    "                x = (x * activation_scale).clamp(-32767, 32767).round().short()\n",
    "            elif isinstance(layer, nn.MaxPool2d):\n",
    "                x = x.float()  # Convert back to Float for pooling\n",
    "                x = layer(x)\n",
    "                activation_scale = 32767 / (x.abs().amax() + 1e-8)  # Recompute scale\n",
    "                x = (x * activation_scale).clamp(-32767, 32767).round().short()  # Requantize\n",
    "            elif isinstance(layer, nn.ReLU):\n",
    "                x = x.float()  # Convert back to Float for ReLU\n",
    "                x = layer(x)\n",
    "                activation_scale = 32767 / (x.abs().amax() + 1e-8)  # Recompute scale\n",
    "                x = (x * activation_scale).clamp(-32767, 32767).round().short()  # Requantize\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Forward pass through classifier\n",
    "        for i, layer in enumerate(model.classifier):\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                key = f\"classifier.{i}.weight\"\n",
    "                activation_scale = 32767 / (x.abs().amax() + 1e-8)\n",
    "                x = F.linear(\n",
    "                    x / activation_scale,\n",
    "                    dequantize_fn(weights_q[key], scales[key])\n",
    "                )\n",
    "                x = (x * activation_scale).clamp(-32767, 32767).round().short()\n",
    "            elif isinstance(layer, nn.ReLU) or isinstance(layer, nn.Dropout):\n",
    "                x = x.float()  # Convert back to Float for ReLU or Dropout\n",
    "                x = layer(x)\n",
    "                activation_scale = 32767 / (x.abs().amax() + 1e-8)  # Recompute scale\n",
    "                x = (x * activation_scale).clamp(-32767, 32767).round().short()  # Requantize\n",
    "\n",
    "        return x\n",
    "\n",
    "# Quantized Model Testing for INT16\n",
    "def test_quantized_per_layer_int16(model, dataloader, device, quantize_fn, dequantize_fn):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = quantized_forward_per_layer_int16(model, inputs, quantize_fn, dequantize_fn)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Quantized Model Accuracy: {accuracy}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Test INT16 Quantized Model\n",
    "print(\"Testing INT16 Quantized Model...\")\n",
    "int16_accuracy = test_quantized_per_layer_int16(\n",
    "    alexnet_fp32, testloader, device, per_layer_quantize_int16, per_layer_dequantize_int16\n",
    ")\n",
    "print(f\"INT16 Quantized Model Accuracy: {int16_accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "391775e4-6ede-400a-9f92-7746bd6e2abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INT8 Quantized Model Accuracy: 83.74%\n",
      "INT16 Quantized Model Accuracy: 83.73%\n",
      "\n",
      "Quantization Results:\n",
      "INT8 Accuracy: 83.74%\n",
      "INT16 Accuracy: 83.73%\n"
     ]
    }
   ],
   "source": [
    "from torch.quantization import quantize_dynamic\n",
    "def quantize_and_test(model, test_loader, quant_type):\n",
    "\n",
    "    # Move the model to CPU for quantization\n",
    "    model.cpu()\n",
    "\n",
    "    if quant_type == 'int8':\n",
    "        quantized_model = quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)  # INT8 quantization\n",
    "    elif quant_type == 'int16':\n",
    "        quantized_model = quantize_dynamic(model, {nn.Linear}, dtype=torch.float16)  # INT16 simulation\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported quantization type: {quant_type}\")\n",
    "\n",
    "    # Test the quantized model\n",
    "    quantized_model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Move data to CPU for testing\n",
    "            images, labels = images.cpu(), labels.cpu()\n",
    "            outputs = quantized_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"{quant_type.upper()} Quantized Model Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Quantized model evaluations\n",
    "quant_types = ['int8', 'int16']\n",
    "quantized_accuracies = {}\n",
    "for qt in quant_types:\n",
    "    quantized_accuracies[qt] = quantize_and_test(alexnet_fp32, testloader, qt)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nQuantization Results:\")\n",
    "for qt, acc in quantized_accuracies.items():\n",
    "    print(f\"{qt.upper()} Accuracy: {acc:.2f}%\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3de08bc4-c6dc-4923-9d83-982daa7e0480",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP32 Model exported to alexnet_fp32_CIFAR.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "\n",
    "# Convert FP32 Model to ONNX\n",
    "def convert_fp32_to_onnx(model, onnx_filename, input_size=(1, 3, 224, 224)):  # Changed to 3 channels\n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(*input_size).to(next(model.parameters()).device)\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_filename,\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        input_names=['input'],\n",
    "        output_names=['output']\n",
    "    )\n",
    "    print(f\"FP32 Model exported to {onnx_filename}\")\n",
    "\n",
    "# Example Usage\n",
    "convert_fp32_to_onnx(alexnet_fp32, \"alexnet_fp32_CIFAR.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973954b-1127-47c2-b7df-9a6e681b2ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.4.0",
   "language": "python",
   "name": "pytorch-2.4.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
