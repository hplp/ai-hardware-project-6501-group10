{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7613ed3a-2aad-446d-a57e-50c5bde30e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4502, Accuracy: 84.51%\n",
      "Epoch [2/10], Loss: 0.0946, Accuracy: 97.20%\n",
      "Epoch [3/10], Loss: 0.0746, Accuracy: 97.83%\n",
      "Epoch [4/10], Loss: 0.0656, Accuracy: 98.07%\n",
      "Epoch [5/10], Loss: 0.0559, Accuracy: 98.38%\n",
      "Epoch [6/10], Loss: 0.0542, Accuracy: 98.43%\n",
      "Epoch [7/10], Loss: 0.0532, Accuracy: 98.52%\n",
      "Epoch [8/10], Loss: 0.0499, Accuracy: 98.63%\n",
      "Epoch [9/10], Loss: 0.0494, Accuracy: 98.58%\n",
      "Epoch [10/10], Loss: 0.0444, Accuracy: 98.75%\n",
      "FP32 Model Trained and Saved.\n",
      "Accuracy: 99.18%\n",
      "FP32 Model Accuracy on MNIST: 99.18%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define AlexNet Model for MNIST\n",
    "class AlexNetMNIST(nn.Module):\n",
    "    def __init__(self, q=False):\n",
    "        super(AlexNetMNIST, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=2),  # Conv1\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),  # Conv2\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),  # Conv3\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),  # Conv4\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),  # Conv5\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),  # FC6\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),  # FC7\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 10),  # FC8 (output for MNIST)\n",
    "        )\n",
    "        self.q = q\n",
    "        if q:\n",
    "            self.quant = torch.quantization.QuantStub()\n",
    "            self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.q:\n",
    "            x = self.quant(x)\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.classifier(x)\n",
    "        if self.q:\n",
    "            x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "# MNIST Dataset Preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize for AlexNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize for grayscale images\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Training Function\n",
    "def train(model, dataloader, epochs=10, cuda=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data\n",
    "            if cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(dataloader):.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Testing Function\n",
    "def test(model, dataloader, cuda=False):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            if cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy}%')\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Train the FP32 Model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "alexnet_fp32 = AlexNetMNIST(q=False).to(device)\n",
    "train(alexnet_fp32, trainloader, epochs=10, cuda=(device == 'cuda'))\n",
    "torch.save(alexnet_fp32.state_dict(), \"alexnet_fp32_mnist.pth\")\n",
    "print(\"FP32 Model Trained and Saved.\")\n",
    "\n",
    "# Test FP32 Model\n",
    "fp32_accuracy = test(alexnet_fp32, testloader, cuda=(device == 'cuda'))\n",
    "print(f\"FP32 Model Accuracy on MNIST: {fp32_accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f663ed-6a56-4af6-b207-1553824d64a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing INT8 Quantized Model...\n",
      "Quantized Model Accuracy: 97.89%\n"
     ]
    }
   ],
   "source": [
    "# Quantization Functions\n",
    "def per_channel_quantize(tensor): #similar to per layer in lenet one\n",
    "    if tensor.ndim == 4:  # For Conv2d weights\n",
    "        scales = 127 / tensor.abs().amax(dim=(1, 2, 3), keepdim=True)\n",
    "        quantized_tensor = (tensor * scales).clamp(-127, 127).round().char()\n",
    "    elif tensor.ndim == 2:  # For Linear weights\n",
    "        scales = 127 / tensor.abs().amax(dim=1, keepdim=True)\n",
    "        quantized_tensor = (tensor * scales).clamp(-127, 127).round().char()\n",
    "    elif tensor.ndim == 1:  # For biases\n",
    "        scales = 127 / tensor.abs().amax(keepdim=True)\n",
    "        quantized_tensor = (tensor * scales).clamp(-127, 127).round().char()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported tensor shape for quantization: {tensor.shape}\")\n",
    "    return quantized_tensor, scales.squeeze()\n",
    "\n",
    "def per_channel_dequantize(quantized_tensor, scales):\n",
    "    if scales.ndim == 1:  # For Linear layers or Conv2D weights\n",
    "        scales = scales[:, None, None, None] if quantized_tensor.ndim == 4 else scales[:, None]\n",
    "    return quantized_tensor.float() / scales\n",
    "\n",
    "# Quantized Forward Pass\n",
    "def quantized_forward(model, x, quantize_fn, dequantize_fn):\n",
    "    with torch.no_grad():\n",
    "        weights_q = {}\n",
    "        scales = {}\n",
    "\n",
    "        # Quantize weights\n",
    "        for name, param in model.named_parameters():\n",
    "            weights_q[name], scales[name] = quantize_fn(param.data)\n",
    "\n",
    "        # Forward pass through features\n",
    "        for i, layer in enumerate(model.features):\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                key = f\"features.{i}.weight\"\n",
    "                activation_scale = 127 / (x.abs().amax() + 1e-8)\n",
    "                x = F.conv2d(\n",
    "                    x / activation_scale,\n",
    "                    dequantize_fn(weights_q[key], scales[key]),\n",
    "                    stride=layer.stride,\n",
    "                    padding=layer.padding\n",
    "                )\n",
    "                x = (x * activation_scale).clamp(-127, 127).round().char()\n",
    "            elif isinstance(layer, nn.MaxPool2d):\n",
    "                x = x.float()  # Convert back to Float for pooling\n",
    "                x = layer(x)\n",
    "                activation_scale = 127 / (x.abs().amax() + 1e-8)  # Recompute scale\n",
    "                x = (x * activation_scale).clamp(-127, 127).round().char()  # Requantize\n",
    "            elif isinstance(layer, nn.ReLU):\n",
    "                x = x.float()  # Convert back to Float for ReLU\n",
    "                x = layer(x)\n",
    "                activation_scale = 127 / (x.abs().amax() + 1e-8)  # Recompute scale\n",
    "                x = (x * activation_scale).clamp(-127, 127).round().char()  # Requantize\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Forward pass through classifier\n",
    "        for i, layer in enumerate(model.classifier):\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                key = f\"classifier.{i}.weight\"\n",
    "                activation_scale = 127 / (x.abs().amax() + 1e-8)\n",
    "                x = F.linear(\n",
    "                    x / activation_scale,\n",
    "                    dequantize_fn(weights_q[key], scales[key])\n",
    "                )\n",
    "                x = (x * activation_scale).clamp(-127, 127).round().char()\n",
    "            elif isinstance(layer, nn.ReLU) or isinstance(layer, nn.Dropout):\n",
    "                x = x.float()  # Convert back to Float for ReLU or Dropout\n",
    "                x = layer(x)\n",
    "                activation_scale = 127 / (x.abs().amax() + 1e-8)  # Recompute scale\n",
    "                x = (x * activation_scale).clamp(-127, 127).round().char()  # Requantize\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Quantized Model Testing\n",
    "def test_quantized(model, dataloader, device, quantize_fn, dequantize_fn):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = quantized_forward(model, inputs, quantize_fn, dequantize_fn)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Quantized Model Accuracy: {accuracy}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Test Quantized Model\n",
    "print(\"Testing INT8 Quantized Model...\")\n",
    "int8_accuracy = test_quantized(alexnet_fp32, testloader, device, per_channel_quantize, per_channel_dequantize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18c2b7cd-9d3a-45ab-bcb1-d8acac3cf4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing INT16 Quantized Model...\n",
      "INT16 Quantized Model Accuracy: 97.95%\n"
     ]
    }
   ],
   "source": [
    "# Extend Quantization Functions for INT16\n",
    "def per_channel_quantize_int16(tensor):\n",
    "    if tensor.ndim == 4:  # For Conv2d weights\n",
    "        scales = 32767 / tensor.abs().amax(dim=(1, 2, 3), keepdim=True)\n",
    "        quantized_tensor = (tensor * scales).clamp(-32767, 32767).round().short()\n",
    "    elif tensor.ndim == 2:  # For Linear weights\n",
    "        scales = 32767 / tensor.abs().amax(dim=1, keepdim=True)\n",
    "        quantized_tensor = (tensor * scales).clamp(-32767, 32767).round().short()\n",
    "    elif tensor.ndim == 1:  # For biases\n",
    "        scales = 32767 / tensor.abs().amax(keepdim=True)\n",
    "        quantized_tensor = (tensor * scales).clamp(-32767, 32767).round().short()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported tensor shape for quantization: {tensor.shape}\")\n",
    "    return quantized_tensor, scales.squeeze()\n",
    "\n",
    "def per_channel_dequantize_int16(quantized_tensor, scales):\n",
    "    if scales.ndim == 1:  # For Linear layers or Conv2D weights\n",
    "        scales = scales[:, None, None, None] if quantized_tensor.ndim == 4 else scales[:, None]\n",
    "    return quantized_tensor.float() / scales\n",
    "\n",
    "# Extend Quantized Forward for INT16\n",
    "def quantized_forward_int16(model, x, quantize_fn, dequantize_fn):\n",
    "    with torch.no_grad():\n",
    "        weights_q = {}\n",
    "        scales = {}\n",
    "\n",
    "        # Quantize weights\n",
    "        for name, param in model.named_parameters():\n",
    "            weights_q[name], scales[name] = quantize_fn(param.data)\n",
    "\n",
    "        # Forward pass through features\n",
    "        for i, layer in enumerate(model.features):\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                key = f\"features.{i}.weight\"\n",
    "                activation_scale = 32767 / (x.abs().amax() + 1e-8)\n",
    "                x = F.conv2d(\n",
    "                    x / activation_scale,\n",
    "                    dequantize_fn(weights_q[key], scales[key]),\n",
    "                    stride=layer.stride,\n",
    "                    padding=layer.padding\n",
    "                )\n",
    "                x = (x * activation_scale).clamp(-32767, 32767).round().short()\n",
    "            elif isinstance(layer, nn.MaxPool2d):\n",
    "                x = x.float()\n",
    "                x = layer(x)\n",
    "                activation_scale = 32767 / (x.abs().amax() + 1e-8)\n",
    "                x = (x * activation_scale).clamp(-32767, 32767).round().short()\n",
    "            elif isinstance(layer, nn.ReLU):\n",
    "                x = x.float()\n",
    "                x = layer(x)\n",
    "                activation_scale = 32767 / (x.abs().amax() + 1e-8)\n",
    "                x = (x * activation_scale).clamp(-32767, 32767).round().short()\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Forward pass through classifier\n",
    "        for i, layer in enumerate(model.classifier):\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                key = f\"classifier.{i}.weight\"\n",
    "                activation_scale = 32767 / (x.abs().amax() + 1e-8)\n",
    "                x = F.linear(\n",
    "                    x / activation_scale,\n",
    "                    dequantize_fn(weights_q[key], scales[key])\n",
    "                )\n",
    "                x = (x * activation_scale).clamp(-32767, 32767).round().short()\n",
    "            elif isinstance(layer, nn.ReLU) or isinstance(layer, nn.Dropout):\n",
    "                x = x.float()\n",
    "                x = layer(x)\n",
    "                activation_scale = 32767 / (x.abs().amax() + 1e-8)\n",
    "                x = (x * activation_scale).clamp(-32767, 32767).round().short()\n",
    "\n",
    "        return x\n",
    "\n",
    "# Extend Quantized Testing for INT16\n",
    "def test_quantized_int16(model, dataloader, device, quantize_fn, dequantize_fn):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = quantized_forward_int16(model, inputs, quantize_fn, dequantize_fn)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"INT16 Quantized Model Accuracy: {accuracy}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Train and Test INT16 Quantized Model\n",
    "print(\"Testing INT16 Quantized Model...\")\n",
    "int16_accuracy = test_quantized_int16(\n",
    "    alexnet_fp32, testloader, device, per_channel_quantize_int16, per_channel_dequantize_int16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df63a0b-35a3-4dd2-8360-25f0c6c5a73e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP32 Model exported to alexnet_fp32_mnist.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "\n",
    "# Convert FP32 Model to ONNX\n",
    "def convert_fp32_to_onnx(model, onnx_filename, input_size=(1, 1, 224, 224)):\n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(*input_size).to(next(model.parameters()).device)\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_filename,\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        input_names=['input'],\n",
    "        output_names=['output']\n",
    "    )\n",
    "    print(f\"FP32 Model exported to {onnx_filename}\")\n",
    "\n",
    "# Example Usage\n",
    "convert_fp32_to_onnx(alexnet_fp32, \"alexnet_fp32_mnist.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.4.0",
   "language": "python",
   "name": "pytorch-2.4.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
